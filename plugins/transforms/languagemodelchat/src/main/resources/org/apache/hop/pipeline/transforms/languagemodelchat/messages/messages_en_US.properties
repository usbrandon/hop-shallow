#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
LanguageModelChat.ClassName=Language Model Chat
BaseTransform.TypeLongDesc.LanguageModelChat=Language Model Chat
BaseTransform.TypeTooltipDesc.LanguageModelChat=A plugin to interact with Large Language Models chat APIs
LanguageModelChatDialog.Shell.Title=Language Model Chat

LanguageModelChat.Exception.CouldnotFindField=Couldn''t find field ''{0}'' in row\!
LanguageModelChat.LineNumber=linenr {0}
LanguageModelChat.ErrorInTransformRunning=Because of an error, this transform can''t continue\: 
LanguageModelChatDialog.TransformName.Label=Transform name 
LanguageModelChatDialog.FailedToGetFields.DialogTitle=Get fields failed
LanguageModelChatDialog.FailedToGetFields.DialogMessage=Unable to get fields from previous transforms because of an error
LanguageModelChatMeta.Exception.UnableToReadTransformMeta=Unable to read transform information from XML

LanguageModelChatMeta.CheckResult.NoInpuReceived=No input received from other transforms\!
LanguageModelChat.Log.UnexpectedError=Unexpected error in ''
LanguageModelChat.Log.ErrorFindingField=Error finding field\: 
LanguageModelChatMeta.CheckResult.CouldNotReadFields=Couldn''t read fields from the previous transform.
LanguageModelChatMeta.CheckResult.ReceivingInfoFromOtherTransforms=Transform is receiving info from other transforms.
LanguageModelChatMeta.CheckResult.ErrorOccurred=An error occurred\:

LanguageModelChatDialog.InputFieldName.Label=Input field name
LanguageModelChatDialog.InputFieldName.Tooltip=The name of the field holding the input text/prompt.
LanguageModelChatMeta.CheckResult.InputFieldOK=Input field was specified.
LanguageModelChat.Error.InputFieldMissing=Input field is missing\!
LanguageModelChatMeta.CheckResult.InputFieldMissing=Input field is missing\!

LanguageModelChatDialog.OutputFieldNamePrefixName.Label=Output field name prefix
LanguageModelChatDialog.OutputFieldNamePrefixName.Tooltip=A prefix applied to all output field names.
LanguageModelChatMeta.CheckResult.OutputFieldNamePrefixOK=Output field name prefix was specified.
LanguageModelChat.Error.OutputFieldNamePrefixMissing=Output field name prefix is missing\!
LanguageModelChatMeta.CheckResult.OutputFieldNamePrefixMissing=Output field name prefix is missing\!

LanguageModelChatDialog.InputChatJson.Label=Input JSON Chat
LanguageModelChatDialog.InputChatJson.Tooltip=When enabled, uses the chat completion JSON format (system, assistant, user messages). When disabled, treats the input as plain text.
LanguageModelChatDialog.OutputChatJson.Label=Output JSON Chat
LanguageModelChatDialog.OutputChatJson.Tooltip=When enabled, returns the response in chat completion JSON format. When disabled, returns the response as plain text.
LanguageModelChatDialog.ModelType.Label=Model API
LanguageModelChatDialog.ModelType.Tooltip=Defines the API used for communication with the endpoint.
LanguageModelChatDialog.Identifier.Label=Identifier value (optional)
LanguageModelChatDialog.Identifier.Tooltip=An optional identifier to label the output records; if left blank, the output will default to the model's name.

LanguageModelChatDialog.OPEN_AI.BaseUrl.Label=API URL
LanguageModelChatDialog.OPEN_AI.BaseUrl.Tooltip=Specifies the base URL used for sending requests to the model provider's API service.
LanguageModelChatDialog.OPEN_AI.ApiKey.Label=API key parameter
LanguageModelChatDialog.OPEN_AI.ApiKey.Tooltip=Unique access value used to authenticate and authorise access to the endpoint service.
LanguageModelChatDialog.OPEN_AI.ModelName.Label=Model name
LanguageModelChatDialog.OPEN_AI.ModelName.Tooltip=Identifies which specific model to use.
LanguageModelChatDialog.OPEN_AI.Temperature.Label=Temperature
LanguageModelChatDialog.OPEN_AI.Temperature.Tooltip=Controls the randomness of the model's responses; higher values produce more creative outputs.
LanguageModelChatDialog.OPEN_AI.Organisation.Label=Organisation
LanguageModelChatDialog.OPEN_AI.Organisation.Tooltip=The organisation ID associated with the API key, for account and billing purposes.
LanguageModelChatDialog.OPEN_AI.TopP.Label=Top P
LanguageModelChatDialog.OPEN_AI.TopP.Tooltip=Limits output diversity by restricting the model's choices to the top tokens within a specified probability mass (e.g., 0.2 considers tokens in the top 20%).
LanguageModelChatDialog.OPEN_AI.MaxTokens.Label=Max tokens
LanguageModelChatDialog.OPEN_AI.MaxTokens.Tooltip=Sets a limit on how many tokens the model may generate in one response.
LanguageModelChatDialog.OPEN_AI.PresencePenalty.Label=Presence penalty
LanguageModelChatDialog.OPEN_AI.PresencePenalty.Tooltip=Applies a one-time additive penalty to tokens that have appeared at least once.
LanguageModelChatDialog.OPEN_AI.FrequencyPenalty.Label=Frequency penalty
LanguageModelChatDialog.OPEN_AI.FrequencyPenalty.Tooltip=Adjusts how the model evaluates token frequency in the generated text, encouraging the model to use less/more repetitive language.
LanguageModelChatDialog.OPEN_AI.ResponseFormat.Label=Response format
LanguageModelChatDialog.OPEN_AI.ResponseFormat.Tooltip=Defines the structure used for the model's responses. If using JSON, you may need to explicitly instructing the model to produce JSON to ensure proper functionality.
LanguageModelChatDialog.OPEN_AI.Seed.Label=Seed
LanguageModelChatDialog.OPEN_AI.Seed.Tooltip=Attempts to sample deterministically, ensuring consistent results for repeated requests with the same seed, prompt, and parameters (e.g. temperature).
LanguageModelChatDialog.OPEN_AI.User.Label=User
LanguageModelChatDialog.OPEN_AI.User.Tooltip=A unique identifier for the end-user, used by the endpoint provider to monitor activity and detect potential abuse.
LanguageModelChatDialog.OPEN_AI.Timeout.Label=Timeout (seconds)
LanguageModelChatDialog.OPEN_AI.Timeout.Tooltip=Determines how long to wait for a response before giving up.
LanguageModelChatDialog.OPEN_AI.MaxRetries.Label=Max retries
LanguageModelChatDialog.OPEN_AI.MaxRetries.Tooltip=The maximum number of retry attempts for failed API requests.
LanguageModelChatDialog.OPEN_AI.UseProxy.Label=Use proxy
LanguageModelChatDialog.OPEN_AI.UseProxy.Tooltip=Routes requests through a proxy server.
LanguageModelChatDialog.OPEN_AI.ProxyHost.Label=Proxy host
LanguageModelChatDialog.OPEN_AI.ProxyHost.Tooltip=The hostname or IP address of the proxy server to use for API requests.
LanguageModelChatDialog.OPEN_AI.ProxyPort.Label=Proxy port
LanguageModelChatDialog.OPEN_AI.ProxyPort.Tooltip=The port number on the proxy server to use for routing API requests.
LanguageModelChatDialog.OPEN_AI.LogRequests.Label=Log requests
LanguageModelChatDialog.OPEN_AI.LogRequests.Tooltip=Used for debugging requests.
LanguageModelChatDialog.OPEN_AI.LogResponses.Label=Log responses
LanguageModelChatDialog.OPEN_AI.LogResponses.Tooltip=Used for debugging responses.

LanguageModelChatDialog.HUGGING_FACE.AccessToken.Label=Access token parameter
LanguageModelChatDialog.HUGGING_FACE.AccessToken.Tooltip=Unique access value used to authenticate and authorise access to the endpoint service.
LanguageModelChatDialog.HUGGING_FACE.ModelId.Label=Model ID / Endpoint URL
LanguageModelChatDialog.HUGGING_FACE.ModelId.Tooltip=Specifies the model ID or URL of the Hugging Face model endpoint to be used.
LanguageModelChatDialog.HUGGING_FACE.Temperature.Label=Temperature
LanguageModelChatDialog.HUGGING_FACE.Temperature.Tooltip=Controls the randomness of the output: high values lead to more diverse text (creative/inventive), while low values produce more focused and deterministic responses.
LanguageModelChatDialog.HUGGING_FACE.MaxNewTokens.Label=Max new tokens
LanguageModelChatDialog.HUGGING_FACE.MaxNewTokens.Tooltip=Sets a limit on how many tokens the model may generate in one response.
LanguageModelChatDialog.HUGGING_FACE.Timeout.Label=Timeout
LanguageModelChatDialog.HUGGING_FACE.Timeout.Tooltip=Determines how long to wait for a response before giving up.
LanguageModelChatDialog.HUGGING_FACE.ReturnFullText.Label=Return full text
LanguageModelChatDialog.HUGGING_FACE.ReturnFullText.Tooltip=Ensures the entire generated text is returned without truncation.
LanguageModelChatDialog.HUGGING_FACE.WaitForModel.Label=Wait for model
LanguageModelChatDialog.HUGGING_FACE.WaitForModel.Tooltip=Delays response until the model is ready. If the model is cold and needs loading, this avoids repeated requests by waiting for it to become available.

LanguageModelChatDialog.OLLAMA.ImageEndpoint.Label=Image/Endpoint
LanguageModelChatDialog.OLLAMA.ImageEndpoint.Tooltip=The URL of the active Ollama service (e.g., http://localhost:11434).
LanguageModelChatDialog.OLLAMA.ModelName.Label=Model Name
LanguageModelChatDialog.OLLAMA.ModelName.Tooltip=Identifies which specific model to use.
LanguageModelChatDialog.OLLAMA.Temperature.Label=Temperature
LanguageModelChatDialog.OLLAMA.Temperature.Tooltip=Controls the randomness of the output: high values lead to more diverse text (creative/inventive), while low values produce more focused and deterministic responses.
LanguageModelChatDialog.OLLAMA.TopK.Label=Top K
LanguageModelChatDialog.OLLAMA.TopK.Tooltip=Limits the number of highest probability tokens considered at each step, reducing the range of possible outcomes.
LanguageModelChatDialog.OLLAMA.TopP.Label=Top P
LanguageModelChatDialog.OLLAMA.TopP.Tooltip=Limits output diversity by restricting the model's choices to the top tokens within a specified probability mass (e.g., 0.2 considers tokens in the top 20%).
LanguageModelChatDialog.OLLAMA.RepeatPenalty.Label=Repeat Penalty
LanguageModelChatDialog.OLLAMA.RepeatPenalty.Tooltip=Adjusts how the model evaluates token frequency in the generated text, encouraging the model to use less/more repetitive language.
LanguageModelChatDialog.OLLAMA.Seed.Label=Seed
LanguageModelChatDialog.OLLAMA.Seed.Tooltip=Attempts to sample deterministically, ensuring consistent results for repeated requests with the same seed, prompt, and parameters.
LanguageModelChatDialog.OLLAMA.NumPredict.Label=Max Tokens
LanguageModelChatDialog.OLLAMA.NumPredict.Tooltip=Sets a limit on how many tokens the model may generate in one response.
LanguageModelChatDialog.OLLAMA.NumCtx.Label=Context Window Size
LanguageModelChatDialog.OLLAMA.NumCtx.Tooltip=Specifies how much input tokens the model can consider at once.
LanguageModelChatDialog.OLLAMA.Format.Label=Format
LanguageModelChatDialog.OLLAMA.Format.Tooltip=Specifies the response format, such as plain text or JSON.
LanguageModelChatDialog.OLLAMA.Timeout.Label=Timeout
LanguageModelChatDialog.OLLAMA.Timeout.Tooltip=Determines how long to wait for a response before giving up.
LanguageModelChatDialog.OLLAMA.MaxRetries.Label=Max Retries
LanguageModelChatDialog.OLLAMA.MaxRetries.Tooltip=The maximum number of retry attempts for failed API requests.

LanguageModelChatDialog.MISTRAL.BaseUrl.Label=Base URL
LanguageModelChatDialog.MISTRAL.BaseUrl.Tooltip=Specifies the base URL used for sending requests to the model provider's API service.
LanguageModelChatDialog.MISTRAL.ApiKey.Label=API Key
LanguageModelChatDialog.MISTRAL.ApiKey.Tooltip=Unique access value used to authenticate and authorise access to the endpoint service.
LanguageModelChatDialog.MISTRAL.ModelName.Label=Model Name
LanguageModelChatDialog.MISTRAL.ModelName.Tooltip=Identifies which specific model to use.
LanguageModelChatDialog.MISTRAL.Temperature.Label=Temperature
LanguageModelChatDialog.MISTRAL.Temperature.Tooltip=Controls the randomness of the output: high values lead to more diverse text (creative/inventive), while low values produce more focused and deterministic responses.
LanguageModelChatDialog.MISTRAL.TopP.Label=Top P
LanguageModelChatDialog.MISTRAL.TopP.Tooltip=Limits output diversity by restricting the model's choices to the top tokens within a specified probability mass (e.g., 0.2 considers tokens in the top 20%).
LanguageModelChatDialog.MISTRAL.MaxTokens.Label=Max Tokens
LanguageModelChatDialog.MISTRAL.MaxTokens.Tooltip=Sets a limit on how many tokens the model may generate in one response.
LanguageModelChatDialog.MISTRAL.SafePrompt.Label=Safe Prompt
LanguageModelChatDialog.MISTRAL.SafePrompt.Tooltip=Provides a baseline prompt to guide the model towards generating safe outputs.
LanguageModelChatDialog.MISTRAL.Seed.Label=Seed
LanguageModelChatDialog.MISTRAL.Seed.Tooltip=Attempts to sample deterministically, ensuring consistent results for repeated requests with the same seed, prompt, and parameters.
LanguageModelChatDialog.MISTRAL.ResponseFormat.Label=Response Format
LanguageModelChatDialog.MISTRAL.ResponseFormat.Tooltip=Defines the structure used for the model's responses. If using JSON, you may need to explicitly instructing the model to produce JSON to ensure proper functionality.
LanguageModelChatDialog.MISTRAL.Timeout.Label=Timeout
LanguageModelChatDialog.MISTRAL.Timeout.Tooltip=Determines how long to wait for a response before giving up.
LanguageModelChatDialog.MISTRAL.LogRequests.Label=Log Requests
LanguageModelChatDialog.MISTRAL.LogRequests.Tooltip=Used for debugging requests.
LanguageModelChatDialog.MISTRAL.LogResponses.Label=Log Responses
LanguageModelChatDialog.MISTRAL.LogResponses.Tooltip=Used for debugging responses.
LanguageModelChatDialog.MISTRAL.MaxRetries.Label=Max Retries
LanguageModelChatDialog.MISTRAL.MaxRetries.Tooltip=The maximum number of retry attempts for failed API requests.

LanguageModelChatDialog.ANTHROPIC.BaseUrl.Label=Base URL
LanguageModelChatDialog.ANTHROPIC.BaseUrl.Tooltip=Specifies the base URL used for sending requests to the model provider's API service.
LanguageModelChatDialog.ANTHROPIC.ApiKey.Label=API Key
LanguageModelChatDialog.ANTHROPIC.ApiKey.Tooltip=Unique access value used to authenticate and authorise access to the endpoint service.
LanguageModelChatDialog.ANTHROPIC.Version.Label=Version
LanguageModelChatDialog.ANTHROPIC.Version.Tooltip=The version of the Anthropic API being used.
LanguageModelChatDialog.ANTHROPIC.ModelName.Label=Model Name
LanguageModelChatDialog.ANTHROPIC.ModelName.Tooltip=Identifies which specific model to use.
LanguageModelChatDialog.ANTHROPIC.Temperature.Label=Temperature
LanguageModelChatDialog.ANTHROPIC.Temperature.Tooltip=Controls the randomness of the output: high values lead to more diverse text (creative/inventive), while low values produce more focused and deterministic responses.
LanguageModelChatDialog.ANTHROPIC.TopP.Label=Top P
LanguageModelChatDialog.ANTHROPIC.TopP.Tooltip=Limits output diversity by restricting the model's choices to the top tokens within a specified probability mass (e.g., 0.2 considers tokens in the top 20%).
LanguageModelChatDialog.ANTHROPIC.TopK.Label=Top K
LanguageModelChatDialog.ANTHROPIC.TopK.Tooltip=Limits the range of possible answers by restricting the number of tokens considered to a fixed amount.
LanguageModelChatDialog.ANTHROPIC.MaxTokens.Label=Max Tokens
LanguageModelChatDialog.ANTHROPIC.MaxTokens.Tooltip=Sets a limit on how many tokens the model may generate in one response.
LanguageModelChatDialog.ANTHROPIC.StopSequences.Label=Stop Sequences
LanguageModelChatDialog.ANTHROPIC.StopSequences.Tooltip=Specifies sequences at which the model should stop generating tokens, effectively ending the response.
LanguageModelChatDialog.ANTHROPIC.Seed.Label=Seed
LanguageModelChatDialog.ANTHROPIC.Seed.Tooltip=Attempts to sample deterministically, ensuring consistent results for repeated requests with the same seed, prompt, and parameters.
LanguageModelChatDialog.ANTHROPIC.Timeout.Label=Timeout
LanguageModelChatDialog.ANTHROPIC.Timeout.Tooltip=Determines how long to wait for a response before giving up.
LanguageModelChatDialog.ANTHROPIC.MaxRetries.Label=Max Retries
LanguageModelChatDialog.ANTHROPIC.MaxRetries.Tooltip=The maximum number of retry attempts for failed API requests.
LanguageModelChatDialog.ANTHROPIC.LogRequests.Label=Log Requests
LanguageModelChatDialog.ANTHROPIC.LogRequests.Tooltip=Used for debugging requests.
LanguageModelChatDialog.ANTHROPIC.LogResponses.Label=Log Responses
LanguageModelChatDialog.ANTHROPIC.LogResponses.Tooltip=Used for debugging responses.

LanguageModelChatDialog.Parallelism.Label=Parallelism
LanguageModelChatDialog.Parallelism.Tooltip=The number of parallel threads used for API requests. WARNING: Be mindful of endpoint capacity and associated costs.
LanguageModelChatDialog.Mock.Label=Mock (simulate)
LanguageModelChatDialog.Mock.Tooltip=Enables a test mode that simulates requests/responses without performing real API calls.
LanguageModelChatDialog.MockOutputValue.Label=Mock Output Value
LanguageModelChatDialog.MockOutputValue.Tooltip=A predefined response returned in simulation (mock) mode, used when real API calls are skipped.

LanguageModelChatDialog.ModelType.OPEN_AI=OpenAI
LanguageModelChatDialog.ModelType.ANTHROPIC=Anthropic
LanguageModelChatDialog.ModelType.OLLAMA=Ollama
LanguageModelChatDialog.ModelType.MISTRAL=Mistral
LanguageModelChatDialog.ModelType.HUGGING_FACE=Hugging Face
