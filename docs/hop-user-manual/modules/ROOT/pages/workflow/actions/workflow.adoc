////
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at
  http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
////
:documentationPath: /workflow/actions/
:language: en_US
:description: The Workflow action executes a previously defined workflow from the current workflow.

:openvar: ${
:closevar: }

= Workflow

== Description

The `Workflow` action executes a previously defined workflow as a child workflow of the current one.

For ease of use, it is also possible to create a new workflow within the dialog, pressing the New Workflow button.

Use the Workflow action to execute a previously defined workflow.

This allows you to perform "functional decomposition." That is, you use them to break out workflows into more manageable units.

For example, you should not write a data warehouse load using one workflow that contains 500 actions.

It is better to create smaller workflows and compose them.

See also:

* The xref:workflow/actions/pipeline.adoc[Pipeline action] that executes a pipeline from a workflow.
* The xref:pipeline/transforms/workflow-executor.adoc[Workflow Executor transform] that executes a workflow from a pipeline.
* The xref:pipeline/transforms/pipeline-executor.adoc[Pipeline Executor transform] that executes a sub-pipeline from a pipeline.

== Options

=== Main workflow options

[options="header", width="90%", cols="1,3"]
|===
|Option|Description
|Action name|Name of the action.
|Workflow Filename a|Specify the XML file name of the workflow to execute. Click to browse through your local files.

The selected workflow will automatically converted to a path relative to your `{openvar}PROJECT_HOME{closevar}`.

For example, if your `{openvar}PROJECT_HOME{closevar}` is `/home/admin/hop/project/` and you select a workflow `/home/admin/hop/project/subfolder/sub.hwf` than the path will automatically be converted to `{openvar}PROJECT_HOME{closevar}/subfolder/sub.hwf`.

|Run configuration a|The xref:metadata-types/workflow-run-config.adoc[workflow run configuration] to use for this workflow action.  
|===

=== Options Tab

[%header, cols="1,3,1", width="90%"]
|===
|Option|Description|Default
|Execute for every input row?|Implements looping; if the previous workflow action returns a set of result rows, the workflow executes once for every row found.
One row is passed to the workflow at every execution.
For example, you can execute a workflow for each file found in a directory.|false
|Wait for the remote workflow to finish?|Enable to block until the workflow on the Hop Server has finished|true
|===

=== Logging Settings Tab

By default, if you do not set logging, Hop will take log actions that are being generated and create a log record inside the workflow.

For example, suppose a workflow has three pipelines to run and you have not set logging.
The pipelines will not output logging information to other files, locations, or special configuration.

In this instance, the workflow executes and puts logging information into its master workflow log.

In most instances, it is acceptable for logging information to be available in the workflow log. +
For example, if you have load dimensions, you want logs for your load dimension runs to display in the workflow logs.
If there are errors in the pipelines, they will be displayed in the workflow logs.
If, however, you want all your log information kept in one place, you must set up logging.

[options="header",cols="1,3", width="90%"]
|===
|Option|Description
|Specify logfile?|Enable to specify a separate logging file for the execution of this workflow
|Name of logfile|The directory and base name of the log file; for example `C:\logs`
|Extension of logfile|The file name extension; for example, log or txt
|Loglevel|Specifies the logging level for the execution of the workflow. See xref:logging/logging-basics.adoc[Logging] for more details.
|Append logfile?|Enable to append to the logfile as opposed to creating a new one
|Create parent folder|Create the parent folder for the log file if it does not exist
|Include date in logfile?|Adds the system date to the filename with format YYYYMMDD (eg 20051231).
|Include time in logfile?|Adds the system time to the filename with format HHMMSS (eg 235959).
See also the logging window in Logging.
|===

=== Parameters Tab

Specify which parameters will be passed to the sub-workflow:

[options="header",cols="1,3", width="90%"]
|===
|Option|Description
|Copy results to parameter|results from previous workflows or pipelines are passed down to this workflows action's parameters
|Pass parameter values down to the sub-workflow|Enable this option to pass all parameters of the workflow down to the sub-workflow.
|Parameters|Specify the parameter names that will be passed to the workflow.
|Stream column name|Allows you to capture fields of incoming records of a result set as a parameter.
|Value
a|Allows you to specify the values for the sub-workflow's parameters.
You can do this by:

* Manually typing some text (Ex: ETL workflow)
* Using a parameter to set the value (Ex: `{openvar}Internal.workflow.Name{closevar}`)
* Using a combination of manually specified text and parameter values (Ex: `{openvar}FILE_PREFIX{closevar}_{openvar}FILE_DATE{closevar}.txt`)

|===

